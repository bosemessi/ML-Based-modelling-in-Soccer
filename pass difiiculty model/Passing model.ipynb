{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bosem\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.mlab as mlab\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pandas import json_normalize\n",
    "import os\n",
    "import csv\n",
    "pd.options.mode.chained_assignment = None\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "import scipy  \n",
    "from scipy.cluster import hierarchy as hc\n",
    "from collections import defaultdict\n",
    "from rfpimp import *\n",
    "\n",
    "# Machine learning\n",
    "from sklearn import preprocessing, model_selection, svm, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    " \n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "from dtreeviz.trees import *\n",
    " \n",
    "# Then run the code below if you get an error telling you that graphviz isn't in your system path (Windows users)\n",
    "# https://stackoverflow.com/a/44625895\n",
    "import os\n",
    "your_graphviz_install_directory = 'C:/Users/bosem/anaconda3/Library/bin/graphviz'\n",
    "os.environ[\"PATH\"] += os.pathsep + your_graphviz_install_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bosem\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (41,122) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "passes = pd.read_csv('Passesfrom11seasons.csv')\n",
    "passes['location'] = passes['location'].astype(str).str.strip('[]')\n",
    "passes['y_loc'] = passes['location'].str.split(', ').str.get(0).str.strip().astype(float)\n",
    "passes['x_loc'] = passes['location'].str.split(', ').str.get(1).str.strip().astype(float)\n",
    "passes['pass_end_location'] = passes['pass_end_location'].astype(str).str.strip('[]')\n",
    "passes['end_y_loc'] = passes['pass_end_location'].str.split(', ').str.get(0).str.strip().astype(float)\n",
    "passes['end_x_loc'] = passes['pass_end_location'].str.split(', ').str.get(1).str.strip().astype(float)\n",
    "# Reset index\n",
    "passes = passes.reset_index().drop('level_0', axis=1)\n",
    "# Create succes column\n",
    "passes.loc[passes['pass_outcome_name'].isnull(),'success'] = 1\n",
    "passes.loc[passes['pass_outcome_name'].notnull(), 'success'] = 0\n",
    "passes['x_dist'] = passes['end_x_loc'] - passes['x_loc'] + 1e-5\n",
    "passes['y_dist'] = passes['end_y_loc'] - passes['y_loc']\n",
    "passes['distance'] = np.sqrt((passes['x_dist']**2 + passes['y_dist']**2))\n",
    "passes['angle'] = np.abs(np.arctan2(passes['y_dist'],passes['x_dist']))\n",
    "feature_cols = ['duration', 'angle', 'pass_body_part_name', 'x_loc', 'y_loc', 'end_x_loc','end_y_loc',\n",
    "                'pass_cross', 'pass_cut_back', 'pass_deflected', 'pass_height_name', 'distance', \n",
    "                'pass_switch', 'pass_through_ball', 'play_pattern_name', 'under_pressure', 'success']\n",
    "pass_final = passes[feature_cols]\n",
    "bool_cols = ['pass_cross', 'pass_cut_back', 'pass_deflected','pass_switch', 'pass_through_ball','under_pressure']\n",
    "for col in bool_cols:\n",
    "    pass_final[col] = np.where(pass_final[col].isna(), 0, 1)\n",
    "features = pass_final.drop('success', axis=1)\n",
    "labels = pass_final['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = ['duration', 'angle', 'distance','x_loc', 'y_loc', 'end_x_loc','end_y_loc'] \n",
    "cat_features = features.drop(cont_cols, axis=1)\n",
    "cont_features = features[cont_cols]\n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000): \n",
    "        with pd.option_context(\"display.max_columns\", 1000): \n",
    "            display(df.head(20).transpose())\n",
    "def label_encode(df):\n",
    "    # Convert df to label encoded\n",
    "    df_le = pd.DataFrame({col: df[col].astype('category').cat.codes for col in df}, index=df.index)\n",
    "    # Save mappings as a dict\n",
    "    mappings = {col: {n: cat for n, cat in enumerate(df[col].astype('category').cat.categories)} \n",
    "     for col in df}\n",
    "    return df_le, mappings\n",
    "cat_features_le, mappings = label_encode(cat_features)\n",
    "features_le = cont_features.merge(cat_features_le, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier loss: 0.06524\n"
     ]
    }
   ],
   "source": [
    "X = features_le\n",
    "y = labels\n",
    " \n",
    "m = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    " \n",
    "# Define a function to calculate the Brier loss using cross-validation\n",
    "def get_loss(X, y=y, m=m, cv=cv):\n",
    "    scores = cross_val_score(m, X, y, cv=cv, scoring='brier_score_loss')\n",
    "    return np.mean(scores)*-1\n",
    " \n",
    "loss = get_loss(X=X)\n",
    "print('Brier loss:', \"{0:.5f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy.random import rand\n",
    "# from numpy.random import seed\n",
    "# seed(42)\n",
    "# copyX = X + rand(*X.shape) / 100000.0\n",
    "# def dendrogram(X):\n",
    "#     corr = np.round(scipy.stats.spearmanr(X).correlation, 4)\n",
    "#     corr_condensed = hc.distance.squareform(1-corr)\n",
    "#     z = hc.linkage(corr_condensed, method='average')\n",
    "#     fig = plt.figure(figsize=(10,8))\n",
    "#     dendrogram = hc.dendrogram(z, labels=X.columns, \n",
    "#           orientation='right', leaf_font_size=16)\n",
    "#     plt.show()\n",
    "#     return\n",
    "# dendrogram(copyX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = ['x_loc', 'end_x_loc',\n",
    "#          'y_loc', 'end_y_loc',\n",
    "#          'distance', 'duration']\n",
    "# print('original', \"{0:.5f}\".format(loss))\n",
    "# for feat in feats:\n",
    "#     loss_feats = get_loss(X=X.drop(feat, axis=1))   \n",
    "#     print(feat, \"{0:.5f}\".format(loss_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get feature importance using the drop-column method\n",
    "# def get_imp(X, y=y, m=m, cv=cv):\n",
    "#     baseline = get_loss(X=X, y=y, m=m, cv=cv)\n",
    "#     imp = []\n",
    "#     for col in X.columns:\n",
    "#         s = get_loss(X=X.drop(col, axis=1), y=y, m=m, cv=cv)\n",
    "#         change_in_score = s - baseline\n",
    "#         imp.append(change_in_score)\n",
    "#     imp_df = pd.DataFrame(data={'Feature': X.columns, 'Importance': np.array(imp)})\n",
    "#     imp_df = imp_df.set_index('Feature').sort_values('Importance', ascending=False)\n",
    "#     return imp_df\n",
    "\n",
    "# imp1 = get_imp(X=X)\n",
    "# imp1.reset_index().plot('Feature', 'Importance', figsize=(10,6), legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_importances(imp1, imp_range=(min(imp1.values), max(imp1.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create n_estimators vs Brier loss plots for different hyperparameters\n",
    "# Modified from https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# def plot_loss(model_list, min_estimators=10, max_estimators=200):\n",
    "#     # Map a classifier name to a list of (n_estimators, Brier loss) pairs\n",
    "#     loss_rate = OrderedDict((clf_name, []) for clf_name, _ in model_list)\n",
    "\n",
    "#     # Range of 'n_estimators' values to explore\n",
    "#     min_estimators = min_estimators\n",
    "#     max_estimators = max_estimators\n",
    "\n",
    "#     for clf_name, clf in model_list:\n",
    "#         for i in range(min_estimators, max_estimators + 1):\n",
    "#             clf.set_params(n_estimators=i)\n",
    "#             clf.fit(X_train, y_train)\n",
    "\n",
    "#             # Record the Brier loss for each 'n_estimators=i' setting\n",
    "#             y_pred = clf.predict(X_test)\n",
    "#             y_pred_proba = clf.predict_proba(X_test)\n",
    "#             brier = brier_score_loss(y_test, y_pred_proba[:,1])\n",
    "#             loss_rate[clf_name].append((i, brier))\n",
    "    \n",
    "#     # Generate the plot\n",
    "#     plt.figure(figsize=(12,8))\n",
    "    \n",
    "#     for clf_name, clf_err in loss_rate.items():\n",
    "#         xs, ys = zip(*clf_err)\n",
    "#         plt.plot(xs, ys, label=clf_name)\n",
    "\n",
    "#     plt.xlim(min_estimators, max_estimators)\n",
    "#     plt.xlabel(\"n_estimators\")\n",
    "#     plt.ylabel(\"Brier loss\")\n",
    "#     plt.legend(loc=\"upper right\");\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting warm_start=True is necessary for tracking the loss rate during training for different values of n_estimators\n",
    "# max_features = [\n",
    "#     (\"RandomForestClassifier, max_features='sqrt'\",\n",
    "#         RandomForestClassifier(n_estimators=100, warm_start=True, max_features='sqrt', random_state=42)),\n",
    "#     (\"RandomForestClassifier, max_features=0.5\",\n",
    "#         RandomForestClassifier(n_estimators=100, warm_start=True, max_features=0.5, random_state=42)),\n",
    "#     (\"RandomForestClassifier, max_features=None\",\n",
    "#         RandomForestClassifier(n_estimators=100, warm_start=True, max_features=None, random_state=42)),\n",
    "# ]\n",
    "\n",
    "# # Note that 'log2' is another commonly used value of max_features, but in this case it's essentially the same as 'sqrt'\n",
    "# plot_loss(max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fit base model to use for comparison\n",
    "# m = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_features='sqrt', random_state=42)\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# scores = cross_val_score(m, X_train, y_train, cv=cv, scoring='brier_score_loss')\n",
    "# print('Brier loss:', \"{0:.5f}\".format(np.mean(scores)*-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "# params = {\n",
    "#     'min_samples_leaf': [3, 4, 5, 6, 7],\n",
    "#     'max_depth': [7, 8, 9, 10, 11]\n",
    "# }\n",
    "\n",
    "# # Create the grid search model\n",
    "# gs = GridSearchCV(estimator=m, param_grid=params, cv=cv, n_jobs=-1,\n",
    "#                   scoring='brier_score_loss', return_train_score=True)\n",
    "\n",
    "# # Fit gs\n",
    "# gs.fit(X_train, y_train)\n",
    "\n",
    "# # Define function to print the results of the grid search\n",
    "# def print_gs_results(gs, print_all=True):\n",
    "#     if print_all == True:\n",
    "#         print('Grid scores:')\n",
    "#         means = gs.cv_results_['mean_test_score']*-1\n",
    "#         stds = gs.cv_results_['std_test_score']\n",
    "#         for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "#             print(\"%0.5f (+/-%0.05f) for %r\"\n",
    "#                   % (mean, std * 2, params))\n",
    "#         print()\n",
    "#         print('Best:', \"{0:.5f}\".format(gs.best_score_*-1),'using %s' % gs.best_params_)\n",
    "#     else:\n",
    "#         print('Best:', \"{0:.5f}\".format(gs.best_score_*-1),'using %s' % gs.best_params_)\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_gs_results(gs=gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier loss: 0.06331\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(objective='binary:logistic', random_state=42, n_jobs=-1)\n",
    "xgb.fit(X_train, y_train)\n",
    "scores = cross_val_score(xgb, X_train, y_train, cv=cv, scoring='brier_score_loss')\n",
    "print('Brier loss:', \"{0:.5f}\".format(np.mean(scores)*-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "# from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "# params = {\n",
    "#     'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "#     'n_estimators': [int(x) for x in np.linspace(start=100, stop=500, num=9)],\n",
    "#     'max_depth': [i for i in range(3, 10)],\n",
    "#     'min_child_weight': [i for i in range(1, 7)],\n",
    "#     'subsample': [i/10.0 for i in range(6,11)],\n",
    "#     'colsample_bytree': [i/10.0 for i in range(6,11)]\n",
    "# }\n",
    "\n",
    "# # Create the randomised grid search model\n",
    "# # See http://scikit-learn.sourceforge.net/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html\n",
    "# # \"n_iter = number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution\"\n",
    "# rgs = RandomizedSearchCV(estimator=xgb, param_distributions=params, n_iter=20, cv=cv, random_state=42, n_jobs=-1,\n",
    "#                          scoring='brier_score_loss', return_train_score=True)\n",
    "\n",
    "# # Fit rgs\n",
    "# rgs.fit(X_train, y_train)\n",
    "\n",
    "# # Print results\n",
    "# print_gs_results(gs=rgs, print_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual passes: 33385.0\n",
      "Predicted passes (xgb): 33391.86\n",
      "Brier loss (xgb): 0.06395\n"
     ]
    }
   ],
   "source": [
    "# Define a function to help fit models and print the results\n",
    "def print_results(xgb, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    # Fit model\n",
    "    xgb.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    y_pred_proba_xgb = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Print results\n",
    "    print('Actual passes:', sum(y_test))\n",
    "    print('Predicted passes (xgb):', '{0:.2f}'.format(sum(y_pred_proba_xgb)))\n",
    "    print('Brier loss (xgb):', '{0:.5f}'.format(brier_score_loss(y_test, y_pred_proba_xgb)))\n",
    "    return\n",
    "\n",
    "# Evaluate best models on the hold-out set\n",
    "# best_xgb = rgs.best_estimator_\n",
    "\n",
    "print_results(xgb=xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrated_xgb = CalibratedClassifierCV(rgs.best_estimator_, cv=cv, method='sigmoid')\n",
    "\n",
    "# print_results(xgb=calibrated_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'final_model2.sav'\n",
    "pickle.dump(xgb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x25d587ed0c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix \n",
    "plot_confusion_matrix(xgb, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
